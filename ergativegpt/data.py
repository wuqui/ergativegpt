# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_data.ipynb.

# %% auto 0
__all__ = ['read_linguistic_data', 'load_experiment_data']

# %% ../nbs/02_data.ipynb 3
import pandas as pd
from pathlib import Path
from typing import Set, Union

# %% ../nbs/02_data.ipynb 4
def read_linguistic_data(fp: Union[str, Path], 
                        expected_columns: Set[str] = None) -> pd.DataFrame:
    """Read and validate linguistic corpus data from Excel files.
    
    Args:
        fp: Path to Excel file
        expected_columns: Set of required column names. If None, uses default set.
    
    Returns:
        Cleaned DataFrame with validated columns
    
    Raises:
        ValueError: If required columns are missing
    """
    if expected_columns is None:
        # Default columns for 2025-05-19 format
        expected_columns = {
            'ID', 'text', 
            'transitivity', 'causativity', 'subject_animacy', 'subject_role',
            'gpt_transitivity', 'gpt_causativity', 'gpt_subject_animacy', 'gpt_subject_role',
            'pos', 'gpt_pos'
        }
    
    df = pd.read_excel(fp) 
    
    # Remove trailing spaces from column headers
    df.columns = df.columns.str.strip()
    
    # Check if all columns are present
    missing_columns = expected_columns - set(df.columns)
    if missing_columns:
        raise ValueError(f'{fp}: Missing required columns: {missing_columns}')
    
    # Replace non-breaking spaces with spaces
    df['text'] = df['text'].str.replace('\xa0', ' ', regex=False)  
    
    return df

# %% ../nbs/02_data.ipynb 6
def load_experiment_data(data_dir: Union[str, Path], 
                        pattern: str = "*_sub.xlsx") -> list[Path]:
    """Load all data files matching a pattern from a directory.
    
    Args:
        data_dir: Directory containing data files
        pattern: Glob pattern for file matching
        
    Returns:
        List of paths to matching files
    """
    data_dir = Path(data_dir)
    return list(data_dir.glob(pattern))

