{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and validation\n",
    "\n",
    "Functions for loading and validating linguistic corpus data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Set, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_linguistic_data(fp: Union[str, Path], \n",
    "                        expected_columns: Set[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"Read and validate linguistic corpus data from Excel files.\n",
    "    \n",
    "    Args:\n",
    "        fp: Path to Excel file\n",
    "        expected_columns: Set of required column names. If None, uses default set.\n",
    "    \n",
    "    Returns:\n",
    "        Cleaned DataFrame with validated columns\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If required columns are missing\n",
    "    \"\"\"\n",
    "    if expected_columns is None:\n",
    "        # Default columns for 2025-05-19 format\n",
    "        expected_columns = {\n",
    "            'ID', 'text', \n",
    "            'transitivity', 'causativity', 'subject_animacy', 'subject_role',\n",
    "            'gpt_transitivity', 'gpt_causativity', 'gpt_subject_animacy', 'gpt_subject_role',\n",
    "            'pos', 'gpt_pos'\n",
    "        }\n",
    "    \n",
    "    df = pd.read_excel(fp) \n",
    "    \n",
    "    # Remove trailing spaces from column headers\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # Check if all columns are present\n",
    "    missing_columns = expected_columns - set(df.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f'{fp}: Missing required columns: {missing_columns}')\n",
    "    \n",
    "    # Replace non-breaking spaces with spaces\n",
    "    df['text'] = df['text'].str.replace('\\xa0', ' ', regex=False)  \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the data loading functions\n",
    "\n",
    "Let's test our data loading functions with the new format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_experiment_data(data_dir: Union[str, Path], \n",
    "                        pattern: str = \"*_sub.xlsx\") -> list[Path]:\n",
    "    \"\"\"Load all data files matching a pattern from a directory.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing data files\n",
    "        pattern: Glob pattern for file matching\n",
    "        \n",
    "    Returns:\n",
    "        List of paths to matching files\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    return list(data_dir.glob(pattern))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
