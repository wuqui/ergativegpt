{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration management\n",
    "\n",
    "Functions for loading and managing experiment configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Union\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    \"\"\"Configuration for a linguistic annotation experiment.\"\"\"\n",
    "    name: str\n",
    "    date: str\n",
    "    description: str\n",
    "    input_dir: str\n",
    "    pattern: str\n",
    "    prompt_file: str\n",
    "    output_dir: str\n",
    "    model_provider: str\n",
    "    model_name: str\n",
    "    target_verb: str = None\n",
    "    target_file: str = None\n",
    "    batch_size: int = 10\n",
    "    max_retries: int = 3\n",
    "    metrics_config: Dict[str, Dict[str, str]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_config(config_path: Union[str, Path]) -> ExperimentConfig:\n",
    "    \"\"\"Load experiment configuration from a YAML file.\n",
    "    \n",
    "    Args:\n",
    "        config_path: Path to the YAML configuration file\n",
    "        \n",
    "    Returns:\n",
    "        ExperimentConfig object with loaded settings\n",
    "    \"\"\"\n",
    "    with open(config_path, 'r') as f:\n",
    "        config_data = yaml.safe_load(f)\n",
    "    \n",
    "    # Flatten nested structure\n",
    "    experiment = config_data['experiment']\n",
    "    data = config_data['data']\n",
    "    output = config_data['output']\n",
    "    model = config_data['model']\n",
    "    processing = config_data.get('processing', {})\n",
    "    metrics = config_data.get('metrics', {})\n",
    "    \n",
    "    return ExperimentConfig(\n",
    "        name=experiment['name'],\n",
    "        date=experiment['date'],\n",
    "        description=experiment['description'],\n",
    "        input_dir=data['input_dir'],\n",
    "        pattern=data['pattern'],\n",
    "        prompt_file=data['prompt_file'],\n",
    "        output_dir=output['dir'],\n",
    "        model_provider=model['provider'],\n",
    "        model_name=model['name'],\n",
    "        target_verb=processing.get('target_verb'),\n",
    "        target_file=processing.get('target_file'),\n",
    "        batch_size=processing.get('batch_size', 10),\n",
    "        max_retries=processing.get('max_retries', 3),\n",
    "        metrics_config=metrics.get('variables', {})\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test configuration loading\n",
    "\n",
    "try:\n",
    "    config = load_config('../nbs/experiments/config/2025-06-23.yaml')\n",
    "    print(f\"✓ Loaded config: {config.name}\")\n",
    "    print(f\"  Model: {config.model_name}\")\n",
    "    print(f\"  Target: {config.target_verb}\")\n",
    "    \n",
    "    # Test basic validation\n",
    "    assert config.name is not None, \"Config name should not be None\"\n",
    "    assert config.model_name is not None, \"Model name should not be None\"\n",
    "    print(\"✓ Configuration validation passed\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"⚠ Config file not found - this is expected in test environment\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Config test failed: {e}\")\n",
    "    raise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
